{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "# Welcome to Feature Factory for Telstra Network Disruptions\n",
    "\n",
    "Feature factory is an online infrastructure that allows one to quickly prototype and test features for different machine learning problems. \n",
    "\n",
    "Before beginning to use Feature Factory, we highly recommend that you familiarize yourself with what IPython Notebook. IPython Notebook is an interactive python kernel that allows you to run code in different cells. Variables created by the code live in the IPython Notebook python kernel and can be accessed at any time, by any cell. More information can be found at http://ipython.org/notebook.html\n",
    "\n",
    "# Creating your own IPython Notebook\n",
    "\n",
    "To get started with Feature Factory, please clone the Template notebook. To do this, click \"File\"->\"Make a Copy\". This should spawn a new tab within your browser with the copied notebook. Rename the notebook to your liking and make all edits on that notebook.\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "# Telstra Network Disruptions Machine Learning Competition\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "In this competition, you are challenged to predict the severity of service disruptions on Telstra's network. Using a dataset of features from their service logs, you're tasked with predicting if a disruption is a momentary glitch or a total interruption of connectivity.\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset is in a relational format, split among mutliple files. When using **commands.get_sample_dataset()** to retrieve the dataset, the files are provided as a list of *pandas.DataFrame* objects.\n",
    "\n",
    "The following step-by-step example shows this in detail.\n",
    "\n",
    "### Event Type Data\n",
    "\n",
    "\n",
    "|       Data Fields       | Definition |\n",
    "|-------------------------|------------|\n",
    "|ID                   | identifies a unique location-time point|\n",
    "|EventType                | type of event that occured at that ID (can be multiple events per ID)|\n",
    "\n",
    "### Log Feature Data\n",
    "\n",
    "|       Data Fields       | Definition |\n",
    "|-------------------------|------------|\n",
    "|ID                   | identifies a unique location-time point|\n",
    "|Log_Feature               | type of feature logged for that ID|\n",
    "|Volume              | number of times the feature was logged for that ID|\n",
    "\n",
    "\n",
    "### Resource Type Data\n",
    "\n",
    "|       Data Fields       | Definition |\n",
    "|-------------------------|------------|\n",
    "|ID                   | identifies a unique location-time point|\n",
    "|Resource_Type              | type of resource assocaited with that ID|\n",
    "\n",
    "### Severity Type Data\n",
    "\n",
    "|       Data Fields       | Definition |\n",
    "|-------------------------|------------|\n",
    "|ID                   | identifies a unique location-time point|\n",
    "|Severity_Type                | type of severity level logged for that ID|\n",
    "\n",
    "### Training Data\n",
    "\n",
    "|       Data Fields       | Definition |\n",
    "|-------------------------|------------|\n",
    "|ID                   | identifies a unique location-time point|\n",
    "|Location               | identifier of location|\n",
    "|Fault_Severity               | categorical. 0: no fault, 1: a few faults, 2: many faults|\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "## Step-by-Step Example\n",
    "\n",
    "Step 1: Import the feature factory infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from problems.telstra import commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 2: Create a username/password or login into an existing account. If you create an account and it is successful, you don't need to login - you are logged in automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username already exists\n"
     ]
    }
   ],
   "source": [
    "commands.create_user('stair_2', 'mazdaa8351')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user successfully logged in\n"
     ]
    }
   ],
   "source": [
    "commands.login('stair_2', 'mazdaa8351')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 3: To ensure that this notebook is mapped to your username, it is required that you execute the command below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook already registered\n"
     ]
    }
   ],
   "source": [
    "commands.add_notebook('TND_FESM02_stair_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 4: Get a sample dataset. This will allow you to test your feature before running it on the full data in the server. Remember that the dataset as a list of [Pandas DataFrames](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = commands.get_sample_dataset()\n",
    "# dataset[0] <- this refers to the event type data\n",
    "# dataset[1] <- this refers to the log feature data\n",
    "# dataset[2] <- this refers to the resource type data\n",
    "# dataset[3] <- this refers to the severity type data\n",
    "# dataset[4] <- this refers to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6597</td>\n",
       "      <td>event_type 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8011</td>\n",
       "      <td>event_type 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2597</td>\n",
       "      <td>event_type 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>event_type 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>event_type 11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     event_type\n",
       "0  6597  event_type 11\n",
       "1  8011  event_type 15\n",
       "2  2597  event_type 15\n",
       "3  5022  event_type 15\n",
       "4  5022  event_type 11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6597</td>\n",
       "      <td>feature 68</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8011</td>\n",
       "      <td>feature 68</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2597</td>\n",
       "      <td>feature 68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>feature 172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>feature 56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  log_feature  volume\n",
       "0  6597   feature 68       6\n",
       "1  8011   feature 68       7\n",
       "2  2597   feature 68       1\n",
       "3  5022  feature 172       2\n",
       "4  5022   feature 56       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>resource_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6597</td>\n",
       "      <td>resource_type 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8011</td>\n",
       "      <td>resource_type 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2597</td>\n",
       "      <td>resource_type 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>resource_type 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6852</td>\n",
       "      <td>resource_type 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    resource_type\n",
       "0  6597  resource_type 8\n",
       "1  8011  resource_type 8\n",
       "2  2597  resource_type 8\n",
       "3  5022  resource_type 8\n",
       "4  6852  resource_type 8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>severity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6597</td>\n",
       "      <td>severity_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8011</td>\n",
       "      <td>severity_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2597</td>\n",
       "      <td>severity_type 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>severity_type 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6852</td>\n",
       "      <td>severity_type 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    severity_type\n",
       "0  6597  severity_type 2\n",
       "1  8011  severity_type 2\n",
       "2  2597  severity_type 2\n",
       "3  5022  severity_type 1\n",
       "4  6852  severity_type 1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2425</td>\n",
       "      <td>location 812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7034</td>\n",
       "      <td>location 1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2097</td>\n",
       "      <td>location 805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9754</td>\n",
       "      <td>location 114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10538</td>\n",
       "      <td>location 1023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       location\n",
       "0   2425   location 812\n",
       "1   7034  location 1050\n",
       "2   2097   location 805\n",
       "3   9754   location 114\n",
       "4  10538  location 1023"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[4][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 5: Define your feature extraction function.\n",
    "\n",
    "The name you give to the function is the name which will be used later on to register your feature extaction function and the score which it obtains.\n",
    "\n",
    "Your function should simply take in the dataset list as a parameter and output a N x M numpy matrix or pandas dataframe where N is number of store-date pairings and M is the number of features which will be used for the prediction.\n",
    "Bear in mind that sorting is important and that, in order to properly evaluate your function score, extracted features should preserve the order which the store-date pairings have in the sales dataset.\n",
    "\n",
    "Also note that, even though the system allows you to do so, any feature extraction function which makes use of the outcome column will be disqualified.\n",
    "\n",
    "**WARNING:** Your functions have to be self contained!\n",
    "\n",
    "This means that you can use helper functions or import external modules but that any import or variable definition needs to be made within the functions which use them.\n",
    "\n",
    "Cross validation is (intentionally) run in a separated process in order to make sure that this scope pattern is preserved, and will fail if the function uses anything defined somewhere else in the notebook.\n",
    "\n",
    "You might be wondering why we require this. The reason is that the code of your function might be executed and further evaluated in different environments where the variables and modules defined in your notebook will not be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TND_FEOHE01_stair_2(dataset):\n",
    "    # Feature Extraction using Simple One-Hot-Encoder for Telstra Network Disruptions\n",
    "    import pandas as pd\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    dataset[3]['st'] = dataset[3]['severity_type'].astype(\"category\")\n",
    "    dataset[3]['st'].cat.categories = range(5)\n",
    "    dataset[2]['rt'] = dataset[2]['resource_type'].astype(\"category\")\n",
    "    dataset[2]['rt'].cat.categories = range(10)\n",
    "    dataset[1]['lf'] = dataset[1]['log_feature'].astype(\"category\")\n",
    "    dataset[1]['lf'].cat.categories = range(386)\n",
    "    dataset[0]['et'] = dataset[0]['event_type'].astype(\"category\")\n",
    "    dataset[0]['et'].cat.categories = range(53)\n",
    "\n",
    "    df = pd.merge(dataset[4], dataset[3], on = 'id', how = 'inner')\n",
    "    df = pd.merge(df, dataset[2], on = 'id', how = 'inner')\n",
    "    df = pd.merge(df, dataset[1], on = 'id', how = 'inner')\n",
    "    df = pd.merge(df, dataset[0], on = 'id', how = 'inner')\n",
    "    df = df.drop(['location','severity_type','resource_type',\\\n",
    "                          'log_feature','event_type'],axis=1)\n",
    "\n",
    "    enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "    df_enc = pd.DataFrame(data=enc.fit_transform(df[['st','rt','lf','et']].as_matrix()))\n",
    "    df_enc['id'] = df['id']\n",
    "    df_enc = df_enc.groupby(['id'], sort=False).median()\n",
    "    df = df.drop(['st','rt','lf','et'],axis=1)\n",
    "    df = df.groupby(['id'], sort=False).median()\n",
    "    df_enc['vol'] = df['volume']\n",
    "        \n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataset\n",
      "Extracting features\n",
      "Cross validating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62633952888594679"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fdf = TND_FEOHE01_stair_2(dataset)\n",
    "commands.cross_validate(TND_FEOHE01_stair_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 6: Evaluate the score of your feature extraction function before submitting it.\n",
    "\n",
    "You can make use of the cross_validate command as many times a needed in order to have a preview of what the score of your function will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataset\n",
      "Extracting features\n",
      "Cross validating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62633952888594679"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands.cross_validate(TND_FEOHE01_stair_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 7: Register your function in the system\n",
    "\n",
    "Once you are satisfied with the results, you can call the add_feature command passing your function as an argument.\n",
    "This will cross_validate the function again and store your code and your score for future analysis.\n",
    "\n",
    "Again, remember that your function code must be self contained and import or define everything it needs to be run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataset\n",
      "Extracting features\n",
      "Cross validating\n",
      "Your feature TND_FEOHE01_stair_2 scored 0.6263395288859468\n",
      "Feature TND_FEOHE01_stair_2 successfully registered\n"
     ]
    }
   ],
   "source": [
    "commands.add_feature(TND_FEOHE01_stair_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Step 8: (Optional) Modify and update your function code.\n",
    "\n",
    "If you discover that your function can be improved you can add it again into the system as many times as required with the same function name.\n",
    "\n",
    "However, for improved clarity, we recommend you to use this option only to fix problems or make small improvements within a similar approach.\n",
    "\n",
    "So, in case you want start a different feature extraction strategy, we strongly recommend you to register it with a new name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
